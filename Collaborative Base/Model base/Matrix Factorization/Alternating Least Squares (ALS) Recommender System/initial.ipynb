{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DRYOUuAxgpf",
        "outputId": "24b59628-0591-48eb-b0ea-6c2df5710c6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train matrix shape (CSR): (64078, 144804)\n",
            "Train matrix shape (CSC): (64078, 144804)\n",
            "Test matrix shape (COO): (64078, 144804)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix, coo_matrix\n",
        "import scipy.sparse\n",
        "import random\n",
        "\n",
        "\n",
        "train_matrix_path = '../Data/train_matrix.npz'\n",
        "test_matrix_path = '../Data/test_matrix.npz'\n",
        "unique_ids_path = '../Data/unique.npz'\n",
        "\n",
        "# TODO\n",
        "train_matrix_coo = scipy.sparse.load_npz(train_matrix_path)\n",
        "test_matrix_coo = scipy.sparse.load_npz(test_matrix_path)\n",
        "\n",
        "unique_user_ids = np.load(unique_ids_path, allow_pickle=True)['users']\n",
        "unique_item_ids = np.load(unique_ids_path, allow_pickle=True)['items']\n",
        "\n",
        "train_matrix_csr = train_matrix_coo.tocsr()\n",
        "train_matrix_csc = train_matrix_coo.tocsc()\n",
        "\n",
        "\n",
        "print(f\"Train matrix shape (CSR): {train_matrix_csr.shape}\")\n",
        "print(f\"Train matrix shape (CSC): {train_matrix_csc.shape}\")\n",
        "print(f\"Test matrix shape (COO): {test_matrix_coo.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om_l3CNQxgph"
      },
      "source": [
        "<div dir=\"right\">\n",
        "  <h2 align=\"right\" style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "    <font face=\"vazirmatn\" color=\"#0099cc\">\n",
        "      گام اول\n",
        "    </font>\n",
        "  </h2>\n",
        "</div>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazirmatn; font-size:medium\">\n",
        "<font face=\"vazirmatn\" size=3>\n",
        "  برای ساخت ماتریس‌های ویژگی‌های پنهان کاربر (P) و ماتریس ویژگی پنهان آیتم (Q) به تعداد کاربران و آیتم‌ها نیاز داریم. به ترتیب در متغیرهای <code>num_users</code> و <code>num_items</code> تعداد کاربران و آیتم‌ها را ذخیره کنید. برای این‌کار می‌توانید از ابعاد ماتریس <code>train_matrix_csr</code> کمک بگیرید.\n",
        "</font>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJ05wglUxgph",
        "outputId": "967f21de-d6ba-46b8-cf8c-216de596da3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique users: 64078\n",
            "Number of unique items: 144804\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "num_users, num_items = train_matrix_csr.shape\n",
        "\n",
        "print(f\"Number of unique users: {num_users}\")\n",
        "print(f\"Number of unique items: {num_items}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWRCJQd3xgpi"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "k = 5\n",
        "lambda_reg = 10\n",
        "num_epochs = 10\n",
        "log_step = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vbq63_myxgpj"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "P = np.random.rand(num_users, k) * 0.001\n",
        "Q = np.random.rand(num_items, k) * 0.001\n",
        "\n",
        "user_bias = np.zeros(num_users)\n",
        "item_bias = np.zeros(num_items)\n",
        "\n",
        "global_average = np.mean(train_matrix_csr.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4LLKG1ixgpk",
        "outputId": "5f591b02-0a73-4281-a036-f2c0a14062f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7.629935528238631"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "global_average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avuubO30xgpm"
      },
      "outputs": [],
      "source": [
        "def solve_user_features(user_idx, train_matrix_csr, P, Q, user_bias, item_bias, global_average, lambda_reg, k):\n",
        "    \"\"\"\n",
        "    Solves for the latent features and bias of a single user using Least Squares.\n",
        "\n",
        "    Args:\n",
        "        user_idx (int): The mapped index of the user.\n",
        "        train_matrix_csr (csr_matrix): The training interaction matrix (CSR format).\n",
        "        P (np.ndarray): Current user latent feature matrix (num_users, k).\n",
        "        Q (np.ndarray): Current item latent feature matrix (num_items, k).\n",
        "        user_bias (np.ndarray): Current user bias vector (num_users,).\n",
        "        item_bias (np.ndarray): Current item bias vector (num_items,).\n",
        "        global_average (float): The global average rating.\n",
        "        lambda_reg (float): The regularization parameter.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - updated_user_bias (float): The updated bias for the user.\n",
        "            - updated_user_features (np.ndarray): The updated latent features for the user (k,).\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    #--step 1:\n",
        "    #  Get user's observed interactions fron train_matrix_csr\n",
        "    user_row = train_matrix_csr.getrow(user_idx)\n",
        "    rated_item_indices = user_row.indices # Mapped indices of items rated by this user\n",
        "    user_ratings = user_row.data         # Actual ratings given by this user\n",
        "\n",
        "    num_rated_items = len(rated_item_indices)\n",
        "\n",
        "    if num_rated_items == 0:\n",
        "        return user_bias[user_idx], P[user_idx, :]\n",
        "\n",
        "    #--step 2:\n",
        "    #  Get the latent features and biases for the items rated by this user\n",
        "    item_features_subset = Q[rated_item_indices, :] # Shape (num_rated_items, k)\n",
        "    item_biases_subset = item_bias[rated_item_indices] # Shape (num_rated_items,)\n",
        "\n",
        "\n",
        "    #--step 3:\n",
        "    #  Formulate the Least Squares problem: A_u * x_u = b_u\n",
        "\n",
        "    # x_u is the vector of unknowns: [user_bias[user_idx], P[user_idx, 0], ..., P[user_idx, k-1]] (shape k+1)\n",
        "    # A_u has shape (num_rated_items, k+1)\n",
        "    # b_u has shape (num_rated_items,)\n",
        "\n",
        "    #--step 3.1 and 3.2:\n",
        "    # Construct A_u: First column is ones (for the bias term), remaining columns are item features\n",
        "    A_u = np.hstack((np.ones((num_rated_items, 1)), item_features_subset)) # Shape (num_rated_items, k+1)\n",
        "\n",
        "    #--step 3.3:\n",
        "    # Construct b_u: Observed ratings minus global average and item biases\n",
        "    b_u = user_ratings - global_average - item_biases_subset # Shape (num_rated_items,)\n",
        "\n",
        "    # Formulate the normal equations: (A_u^T * A_u + lambda * I) * x_u = A_u^T * b_u\n",
        "    ATA = A_u.T @ A_u # Shape (k+1, k+1)\n",
        "    ATb = A_u.T @ b_u # Shape (k+1,)\n",
        "\n",
        "\n",
        "    #--step 3.4:\n",
        "    # Add regularization term (lambda * I)\n",
        "    # Create an identity matrix of size k+1\n",
        "    regularization_matrix = np.eye(k + 1)\n",
        "    regularization_matrix[0, 0] = 0\n",
        "    # Create ATA_regularized matrix\n",
        "    ATA_regularized = ATA + lambda_reg * regularization_matrix\n",
        "\n",
        "\n",
        "    #--step 4:\n",
        "    # Solve the linear system\n",
        "    # Use np.linalg.solve(matrix, vector)\n",
        "    solution_vector = np.linalg.solve(ATA_regularized, ATb) # Shape (k+1,)\n",
        "\n",
        "    #--step 5:\n",
        "    # Extract the updated bias and latent features from the solution vector\n",
        "    updated_user_bias = solution_vector[0]\n",
        "    updated_user_features = solution_vector[1:] # Shape (k,)\n",
        "\n",
        "    return updated_user_bias, updated_user_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mv6ab9Vdxgpo"
      },
      "outputs": [],
      "source": [
        "def solve_item_features(item_idx, train_matrix_csc, P, Q, user_bias, item_bias, global_average, lambda_reg, k):\n",
        "    \"\"\"\n",
        "    Solves for the latent features and bias of a single item using Least Squares.\n",
        "\n",
        "    Args:\n",
        "        item_idx (int): The mapped index of the item.\n",
        "        train_matrix_csc (csc_matrix): The training interaction matrix (CSC format).\n",
        "        P (np.ndarray): Current user latent feature matrix (num_users, k).\n",
        "        Q (np.ndarray): Current item latent feature matrix (num_items, k).\n",
        "        user_bias (np.ndarray): Current user bias vector (num_users,).\n",
        "        item_bias (np.ndarray): Current item bias vector (num_items,).\n",
        "        global_average (float): The global average rating.\n",
        "        lambda_reg (float): The regularization parameter.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - updated_item_bias (float): The updated bias for the item.\n",
        "            - updated_item_features (np.ndarray): The updated latent features for the item (k,).\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "\n",
        "    #--step 1:\n",
        "    # Get the column for this item from the training matrix\n",
        "    item_col = train_matrix_csc.getcol(item_idx)\n",
        "    rating_user_indices = item_col.indices # Mapped indices of users who rated this item\n",
        "    item_ratings = item_col.data         # Actual ratings given to this item\n",
        "\n",
        "    num_rating_users = len(rating_user_indices)\n",
        "\n",
        "    if num_rating_users == 0:\n",
        "        return item_bias[item_idx], Q[item_idx, :]\n",
        "\n",
        "    #--step 2:\n",
        "    # Get the latent features and biases for the users who rated this item\n",
        "    user_features_subset = P[rating_user_indices, :] # Shape (num_rating_users, k)\n",
        "    user_biases_subset = user_bias[rating_user_indices] # Shape (num_rating_users,)\n",
        "\n",
        "    #--step 3:\n",
        "    # Formulate the Least Squares problem: A_i * x_i = b_i\n",
        "    # x_i is the vector of unknowns: [item_bias[item_idx], Q[item_idx, 0], ..., Q[item_idx, k-1]] (shape k+1)\n",
        "    # A_i has shape (num_rating_users, k+1)\n",
        "    # b_i has shape (num_rating_users,)\n",
        "\n",
        "    # Construct A_i: First column is ones (for the bias term), remaining columns are user features\n",
        "    A_i = np.hstack((np.ones((num_rating_users, 1)), user_features_subset)) # Shape (num_rating_users, k+1)\n",
        "\n",
        "    # Construct b_i: Observed ratings minus global average and user biases\n",
        "    b_i = item_ratings - global_average - user_biases_subset # Shape (num_rating_users,)\n",
        "\n",
        "    # Formulate the normal equations: (A_i^T * A_i + lambda * I) * x_i = A_i^T * b_i\n",
        "    ATA = A_i.T @ A_i # Shape (k+1, k+1)\n",
        "    ATb = A_i.T @ b_i # Shape (k+1,)\n",
        "\n",
        "    # Add regularization term (lambda * I)\n",
        "    regularization_matrix = np.eye(k + 1)\n",
        "    # If not regularizing bias: regularization_matrix[0, 0] = 0\n",
        "    regularization_matrix[0, 0] = 0\n",
        "    ATA_regularized = ATA + lambda_reg * regularization_matrix\n",
        "\n",
        "    #--step 4:\n",
        "    # Solve the linear system\n",
        "    solution_vector = np.linalg.solve(ATA_regularized, ATb) # Shape (k+1,)\n",
        "\n",
        "    #--step 5:\n",
        "    # Extract the updated bias and latent features from the solution vector\n",
        "    updated_item_bias = solution_vector[0]\n",
        "    updated_item_features = solution_vector[1:] # Shape (k,)\n",
        "\n",
        "    return updated_item_bias, updated_item_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZXNEXE4xgpp",
        "outputId": "285babae-b1d9-409d-cf8b-4482857f52c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Predicted rating for mapped user 0 and mapped item 2: 7.6299\n"
          ]
        }
      ],
      "source": [
        "def predict(user_idx, item_idx, P, Q, user_bias, item_bias, global_average):\n",
        "    \"\"\"\n",
        "    Predicts the rating for a given user and item using the trained ALS model.\n",
        "\n",
        "    Args:\n",
        "        user_idx (int): Mapped index of the user.\n",
        "        item_idx (int): Mapped index of the item.\n",
        "        P (np.ndarray): Trained user latent feature matrix (num_users, k).\n",
        "        Q (np.ndarray): Trained item latent feature matrix (num_items, k).\n",
        "        user_bias (np.ndarray): Trained user bias vector (num_users,).\n",
        "        item_bias (np.ndarray): Trained item bias vector (num_items,).\n",
        "        global_average (float): Calculated global average rating.\n",
        "\n",
        "    Returns:\n",
        "        float: The predicted rating.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        predicted_rating = global_average + user_bias[user_idx] + item_bias[item_idx] + np.dot(P[user_idx, :], Q[item_idx, :])\n",
        "        return predicted_rating\n",
        "\n",
        "    except IndexError:\n",
        "        print(\"\\nCould not find mapped index for example prediction. Ensure original IDs exist in unique IDs.\")\n",
        "        return global_average\n",
        "\n",
        "mapped_user_0_idx = 0\n",
        "mapped_item_2_idx = 2\n",
        "predicted_rating_example = predict(mapped_user_0_idx, mapped_item_2_idx, P, Q, user_bias, item_bias, global_average)\n",
        "print(f\"\\nPredicted rating for mapped user {mapped_user_0_idx} and mapped item {mapped_item_2_idx}: {predicted_rating_example:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Iscjtdfxgpq"
      },
      "outputs": [],
      "source": [
        "def calculate_rmse(P, Q, user_bias, item_bias, global_average, matrix_coo):\n",
        "    \"\"\"\n",
        "    Calculates the Root Mean Squared Error (RMSE) on a sparse matrix using the trained ALS model.\n",
        "\n",
        "    Args:\n",
        "        P (np.ndarray): Trained user latent feature matrix.\n",
        "        Q (np.ndarray): Trained item latent feature matrix.\n",
        "        user_bias (np.ndarray): Trained user bias vector.\n",
        "        item_bias (np.ndarray): Trained item bias vector.\n",
        "        global_average (float): Calculated global average rating.\n",
        "        matrix_csr (csr_matrix): The sparse matrix to evaluate on (e.g., test set).\n",
        "\n",
        "    Returns:\n",
        "        float: The calculated RMSE.\n",
        "    \"\"\"\n",
        "    rows = matrix_coo.row\n",
        "    cols = matrix_coo.col\n",
        "    data = matrix_coo.data\n",
        "    num_samples = len(data)\n",
        "\n",
        "    if num_samples == 0:\n",
        "        return 0.0\n",
        "\n",
        "    sse = 0\n",
        "    for idx in range(num_samples):\n",
        "        u = rows[idx]\n",
        "        i = cols[idx]\n",
        "        r_ui = data[idx]\n",
        "\n",
        "        predicted_r_ui = predict(u, i, P, Q, user_bias, item_bias, global_average)\n",
        "\n",
        "        sse += (r_ui - predicted_r_ui)**2\n",
        "\n",
        "    rmse = np.sqrt(sse / num_samples)\n",
        "    return rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfkuuquYxgpr",
        "outputId": "4cc18629-ea52-46bc-8b76-6eea1b65c9b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting ALS training...\n",
            "Iteration 1/10, Train RMSE: 1.0124, Test RMSE: 1.7459\n",
            "Iteration 2/10, Train RMSE: 0.9615, Test RMSE: 1.7650\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[118], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# --- Step 2: Solve for Item Features (Fix P and user_bias) ---\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Iterate through each item\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_items):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# TODO\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     updated_b_i, updated_Q_i \u001b[38;5;241m=\u001b[39m \u001b[43msolve_item_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_matrix_csc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     item_bias[i] \u001b[38;5;241m=\u001b[39m updated_b_i\n\u001b[1;32m     18\u001b[0m     Q[i, :] \u001b[38;5;241m=\u001b[39m updated_Q_i\n",
            "Cell \u001b[0;32mIn[115], line 24\u001b[0m, in \u001b[0;36msolve_item_features\u001b[0;34m(item_idx, train_matrix_csc, P, Q, user_bias, item_bias, global_average, lambda_reg, k)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mSolves for the latent features and bias of a single item using Least Squares.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m        - updated_item_features (np.ndarray): The updated latent features for the item (k,).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# TODO\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#--step 1:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Get the column for this item from the training matrix\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m item_col \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_matrix_csc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m rating_user_indices \u001b[38;5;241m=\u001b[39m item_col\u001b[38;5;241m.\u001b[39mindices \u001b[38;5;66;03m# Mapped indices of users who rated this item\u001b[39;00m\n\u001b[1;32m     26\u001b[0m item_ratings \u001b[38;5;241m=\u001b[39m item_col\u001b[38;5;241m.\u001b[39mdata         \u001b[38;5;66;03m# Actual ratings given to this item\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/scipy/sparse/_matrix.py:133\u001b[0m, in \u001b[0;36mspmatrix.getcol\u001b[0;34m(self, j)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetcol\u001b[39m(\u001b[38;5;28mself\u001b[39m, j):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a copy of column j of the array, as an (m x 1) sparse\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    array (column vector).\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getcol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/scipy/sparse/_csc.py:208\u001b[0m, in \u001b[0;36m_csc_base._getcol\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m N:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) out of range\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m i)\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_submatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmajor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/scipy/sparse/_compressed.py:813\u001b[0m, in \u001b[0;36m_cs_matrix._get_submatrix\u001b[0;34m(self, major, minor, copy)\u001b[0m\n\u001b[1;32m    809\u001b[0m indptr, indices, data \u001b[38;5;241m=\u001b[39m get_csr_submatrix(\n\u001b[1;32m    810\u001b[0m     M, N, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, i0, i1, j0, j1)\n\u001b[1;32m    812\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap((i1 \u001b[38;5;241m-\u001b[39m i0, j1 \u001b[38;5;241m-\u001b[39m j0))\n\u001b[0;32m--> 813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/scipy/sparse/_compressed.py:105\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_check\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/scipy/sparse/_compressed.py:156\u001b[0m, in \u001b[0;36m_cs_matrix.check_format\u001b[0;34m(self, full_check)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    153\u001b[0m     warn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices array has non-integer dtype (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname), stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m--> 156\u001b[0m idx_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_index_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/scipy/sparse/_base.py:1289\u001b[0m, in \u001b[0;36m_spbase._get_index_dtype\u001b[0;34m(self, arrays, maxval, check_contents)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_index_dtype\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;66;03m# Don't check contents for array API\u001b[39;00m\n\u001b[0;32m-> 1289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_index_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_contents\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_array\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/scipy/sparse/_sputils.py:170\u001b[0m, in \u001b[0;36mget_index_dtype\u001b[0;34m(arrays, maxval, check_contents)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mBased on input (integer) arrays `a`, determine a suitable index data\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03mtype that can hold the data in the arrays.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m int32min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint32(np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmin)\n\u001b[0;32m--> 170\u001b[0m int32max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint32(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# not using intc directly due to misinteractions with pythran\u001b[39;00m\n\u001b[1;32m    173\u001b[0m dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint32 \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mintc()\u001b[38;5;241m.\u001b[39mitemsize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mint64\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/numpy/core/getlimits.py:692\u001b[0m, in \u001b[0;36miinfo.__init__\u001b[0;34m(self, int_type)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mitemsize \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m--> 692\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid integer data type \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind,))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(\"\\nStarting ALS training...\")\n",
        "\n",
        "for iteration in range(num_epochs):\n",
        "    # --- Step 1: Solve for User Features (Fix Q and item_bias) ---\n",
        "    # Iterate through each user\n",
        "    for u in range(num_users):\n",
        "        # TODO\n",
        "        updated_b_u, updated_P_u = solve_user_features(u, train_matrix_csr, P, Q, user_bias, item_bias, global_average, lambda_reg, k)\n",
        "        user_bias[u] = updated_b_u\n",
        "        P[u, :] = updated_P_u\n",
        "\n",
        "    # --- Step 2: Solve for Item Features (Fix P and user_bias) ---\n",
        "    # Iterate through each item\n",
        "    for i in range(num_items):\n",
        "        # TODO\n",
        "        updated_b_i, updated_Q_i = solve_item_features(i, train_matrix_csc, P, Q, user_bias, item_bias, global_average, lambda_reg, k)\n",
        "        item_bias[i] = updated_b_i\n",
        "        Q[i, :] = updated_Q_i\n",
        "\n",
        "    if (iteration + 1) % log_step == 0:\n",
        "        train_rmse = calculate_rmse(P, Q, user_bias, item_bias, global_average, train_matrix_coo)\n",
        "        test_rmse = calculate_rmse(P, Q, user_bias, item_bias, global_average, test_matrix_coo)\n",
        "        print(f\"Iteration {iteration+1}/{num_epochs}, Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\nTraining finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0499Woluxgps",
        "outputId": "da4f1f29-5330-4851-d9b2-f83e8eea423c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Predicted rating for mapped user 0 and mapped item 2: 5.6608\n"
          ]
        }
      ],
      "source": [
        "mapped_user_0_idx = 0\n",
        "mapped_item_2_idx = 2\n",
        "predicted_rating_example = predict(mapped_user_0_idx, mapped_item_2_idx, P, Q, user_bias, item_bias, global_average)\n",
        "print(f\"\\nPredicted rating for mapped user {mapped_user_0_idx} and mapped item {mapped_item_2_idx}: {predicted_rating_example:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWaFnqJnxgpt"
      },
      "outputs": [],
      "source": [
        "def get_recommendations(original_user_id, n, P, Q, user_bias, item_bias, global_average, train_matrix_csr, unique_user_ids, unique_item_ids):\n",
        "    \"\"\"\n",
        "    Generates top N recommendations for a given user using the trained ALS model.\n",
        "\n",
        "    Args:\n",
        "        original_user_id: The original ID of the user.\n",
        "        n (int): The number of recommendations to generate.\n",
        "        P (np.ndarray): Trained user latent feature matrix (num_users, k).\n",
        "        Q (np.ndarray): Trained item latent feature matrix (num_items, k).\n",
        "        user_bias (np.ndarray): Trained user bias vector (num_users,).\n",
        "        item_bias (np.ndarray): Trained item bias vector (num_items,).\n",
        "        global_average (float): Calculated global average rating.\n",
        "        train_matrix_csr (csr_matrix): The sparse training interaction matrix.\n",
        "        unique_user_ids (np.ndarray): Array mapping mapped user indices to original IDs.\n",
        "        unique_item_ids (np.ndarray): Array mapping mapped item indices to original IDs.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tuples (original_item_id, predicted_rating) for the top N recommendations.\n",
        "              Returns an empty list if the user ID is not found.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        user_idx = np.where(unique_user_ids == original_user_id)[0][0]\n",
        "    except IndexError:\n",
        "        print(f\"Warning: Original user ID {original_user_id} not found in unique user IDs.\")\n",
        "        return []\n",
        "\n",
        "    num_items = Q.shape[0]\n",
        "    all_item_indices = np.arange(num_items)\n",
        "\n",
        "    user_row_sparse = train_matrix_csr.getrow(user_idx)\n",
        "    rated_item_indices = user_row_sparse.indices\n",
        "\n",
        "\n",
        "    unrated_item_indices = np.setdiff1d(all_item_indices, rated_item_indices)\n",
        "\n",
        "\n",
        "    user_latent_features = P[user_idx, :]\n",
        "    unrated_item_latent_features = Q[unrated_item_indices, :]\n",
        "    unrated_item_biases = item_bias[unrated_item_indices]\n",
        "\n",
        "\n",
        "    latent_predictions = np.dot(user_latent_features, unrated_item_latent_features.T)\n",
        "\n",
        "    predicted_ratings_for_user = global_average + user_bias[user_idx] + unrated_item_biases + latent_predictions\n",
        "\n",
        "    top_n_indices_in_unrated = np.argsort(predicted_ratings_for_user)[::-1][:n]\n",
        "\n",
        "    recommended_mapped_item_indices = unrated_item_indices[top_n_indices_in_unrated]\n",
        "\n",
        "    recommended_items_with_ratings = [(unique_item_ids[item_idx], predicted_ratings_for_user[i])\n",
        "                                      for i, item_idx in enumerate(top_n_indices_in_unrated)]\n",
        "\n",
        "    return recommended_items_with_ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1Lz5r4pxgpt",
        "outputId": "585dcdd5-d62b-450d-8e68-2456852bb448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 5 recommendations for original user ID 8:\n",
            "  Item ID: 1403332258, Predicted Rating: 5.6608\n",
            "  Item ID: 0743230213, Predicted Rating: 5.7960\n",
            "  Item ID: 0064471101, Predicted Rating: 5.6608\n",
            "  Item ID: 0253216141, Predicted Rating: 5.7078\n",
            "  Item ID: 0740723235, Predicted Rating: 6.1188\n"
          ]
        }
      ],
      "source": [
        "original_user_id_to_recommend = 8\n",
        "top_n_recommendations = 5\n",
        "\n",
        "recommendations = get_recommendations(original_user_id_to_recommend, top_n_recommendations, P, Q, user_bias, item_bias, global_average, train_matrix_csr, unique_user_ids, unique_item_ids)\n",
        "\n",
        "if recommendations:\n",
        "    print(f\"\\nTop {top_n_recommendations} recommendations for original user ID {original_user_id_to_recommend}:\")\n",
        "    for item_id, predicted_rating in recommendations:\n",
        "        print(f\"  Item ID: {item_id}, Predicted Rating: {predicted_rating:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_in91LZxgpu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "eval_users_idx = [73,  75,  78,  81,  82,  83,  85,  86,  87,  88,  91,  92,  97,\n",
        "        99, 102, 107, 109, 110, 114, 125]\n",
        "eval_top_n_recommendations = 10\n",
        "eval_recommendations = [get_recommendations(user_idx, eval_top_n_recommendations, P, Q, user_bias, item_bias, global_average, train_matrix_csr, unique_user_ids, unique_item_ids)\n",
        "                        for user_idx in eval_users_idx]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}