{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell 1: Load Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "import scipy.sparse\n",
    "import random\n",
    "\n",
    "\n",
    "train_matrix_path = \"../Data/train_matrix.npz\"\n",
    "test_matrix_path = \"../Data/test_matrix.npz\"\n",
    "unique_ids_path = \"../Data/unique.npz\"\n",
    "\n",
    "train = scipy.sparse.load_npz(train_matrix_path)\n",
    "test = scipy.sparse.load_npz(test_matrix_path)\n",
    "\n",
    "unique_user_ids = np.load(unique_ids_path, allow_pickle=True)[\"users\"]\n",
    "unique_item_ids = np.load(unique_ids_path, allow_pickle=True)[\"items\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matrix shape: (64078, 144804)\n",
      "Test matrix shape: (64078, 144804)\n",
      "Number of unique users: 64078\n",
      "Number of unique items: 144804\n"
     ]
    }
   ],
   "source": [
    "num_users, num_items = train.shape\n",
    "\n",
    "print(f\"Train matrix shape: {train.shape}\")\n",
    "print(f\"Test matrix shape: {test.shape}\")\n",
    "print(f\"Number of unique users: {num_users}\")\n",
    "print(f\"Number of unique items: {num_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: k=100, learning_rate=0.01, lambda_reg=0.8, num_epochs=10, log_step=1\n"
     ]
    }
   ],
   "source": [
    "k = 100\n",
    "learning_rate = 0.01\n",
    "lambda_reg = 0.8\n",
    "num_epochs = 10\n",
    "log_step = 1\n",
    "\n",
    "print(\n",
    "    f\"Hyperparameters: k={k}, learning_rate={learning_rate}, lambda_reg={lambda_reg}, num_epochs={num_epochs}, log_step={log_step}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized P shape: (64078, 100)\n",
      "Initialized Q shape: (100, 144804)\n",
      "Initialized user_bias shape: (64078,)\n",
      "Initialized item_bias shape: (144804,)\n",
      "Calculated global average: 7.6299\n"
     ]
    }
   ],
   "source": [
    "P = np.random.rand(num_users, k) * 0.005\n",
    "Q = np.random.rand(k, num_items) * 0.005\n",
    "\n",
    "\n",
    "user_bias = np.zeros(num_users)\n",
    "item_bias = np.zeros(num_items)\n",
    "\n",
    "global_average = np.mean(train.data)\n",
    "\n",
    "print(f\"Initialized P shape: {P.shape}\")\n",
    "print(f\"Initialized Q shape: {Q.shape}\")\n",
    "print(f\"Initialized user_bias shape: {user_bias.shape}\")\n",
    "print(f\"Initialized item_bias shape: {item_bias.shape}\")\n",
    "print(f\"Calculated global average: {global_average:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined. Now implement the logic inside them!\n"
     ]
    }
   ],
   "source": [
    "def calculate_predicted_rating(\n",
    "    user_idx, item_idx, P, Q, user_bias, item_bias, global_average\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates the predicted rating for a single user-item pair.\n",
    "\n",
    "    Args:\n",
    "        user_idx (int): Mapped index of the user.\n",
    "        item_idx (int): Mapped index of the item.\n",
    "        P (np.ndarray): User latent feature matrix (num_users, k).\n",
    "        Q (np.ndarray): Item latent feature matrix (k, num_items).\n",
    "        user_bias (np.ndarray): User bias vector (num_users,).\n",
    "        item_bias (np.ndarray): Item bias vector (num_items,).\n",
    "        global_average (float): Global average rating.\n",
    "\n",
    "    Returns:\n",
    "        float: The predicted rating.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    predicted_rating = (\n",
    "        global_average\n",
    "        + user_bias[user_idx]\n",
    "        + item_bias[item_idx]\n",
    "        + np.dot(P[user_idx, :], Q[:, item_idx])\n",
    "    )\n",
    "\n",
    "    return predicted_rating\n",
    "\n",
    "\n",
    "def calculate_error(actual_rating, predicted_rating):\n",
    "    \"\"\"\n",
    "    Calculates the prediction error for a single rating.\n",
    "\n",
    "    Args:\n",
    "        actual_rating (float): The actual observed rating.\n",
    "        predicted_rating (float): The predicted rating.\n",
    "\n",
    "    Returns:\n",
    "        float: The prediction error (actual - predicted).\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    error = actual_rating - predicted_rating\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "def update_biases(\n",
    "    user_idx, item_idx, error, user_bias, item_bias, learning_rate, lambda_reg\n",
    "):\n",
    "    \"\"\"\n",
    "    Updates the user and item biases using the calculated error and SGD rules.\n",
    "\n",
    "    Args:\n",
    "        user_idx (int): Mapped index of the user.\n",
    "        item_idx (int): Mapped index of the item.\n",
    "        error (float): The prediction error for the user-item pair.\n",
    "        user_bias (np.ndarray): User bias vector (num_users,).\n",
    "        item_bias (np.ndarray): Item bias vector (num_items,).\n",
    "        learning_rate (float): The learning rate for SGD.\n",
    "        lambda_reg (float): The regularization parameter.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO\n",
    "    user_bias[user_idx] += learning_rate * (error - lambda_reg * user_bias[user_idx])\n",
    "    item_bias[item_idx] += learning_rate * (error - lambda_reg * item_bias[item_idx])\n",
    "\n",
    "\n",
    "def update_latent_features(\n",
    "    user_idx, item_idx, error, P, Q, learning_rate, lambda_reg, k\n",
    "):\n",
    "    \"\"\"\n",
    "    Updates the user and item latent features using the calculated error and SGD rules.\n",
    "\n",
    "    Args:\n",
    "        user_idx (int): Mapped index of the user.\n",
    "        item_idx (int): Mapped index of the item.\n",
    "        error (float): The prediction error for the user-item pair.\n",
    "        P (np.ndarray): User latent feature matrix (num_users, k).\n",
    "        Q (np.ndarray): Item latent feature matrix (k, num_items).\n",
    "        learning_rate (float): The learning rate for SGD.\n",
    "        lambda_reg (float): The regularization parameter.\n",
    "        k (int): The number of latent features.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO\n",
    "    for f in range(k):\n",
    "        p_uf = P[user_idx, f]\n",
    "        q_fi = Q[f, item_idx]\n",
    "\n",
    "        P[user_idx, f] += learning_rate * (error * q_fi - lambda_reg * p_uf)\n",
    "        Q[f, item_idx] += learning_rate * (error * p_uf - lambda_reg * q_fi)\n",
    "\n",
    "\n",
    "print(\"Helper functions defined. Now implement the logic inside them!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/10, Train RMSE: 1.6958, Test RMSE: 1.7181\n",
      "Epoch 2/10, Train RMSE: 1.6507, Test RMSE: 1.6950\n",
      "Epoch 3/10, Train RMSE: 1.6188, Test RMSE: 1.6814\n",
      "Epoch 4/10, Train RMSE: 1.5934, Test RMSE: 1.6728\n",
      "Epoch 5/10, Train RMSE: 1.5726, Test RMSE: 1.6672\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 27\u001b[0m\n\u001b[1;32m     21\u001b[0m     error \u001b[38;5;241m=\u001b[39m calculate_error(r_ui, predicted_r_ui)\n\u001b[1;32m     24\u001b[0m     update_biases(u, i, error, user_bias, item_bias, learning_rate, lambda_reg)\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mupdate_latent_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m log_step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     31\u001b[0m     train_sse \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# Sum of Squared Errors for the current epoch\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 77\u001b[0m, in \u001b[0;36mupdate_latent_features\u001b[0;34m(user_idx, item_idx, error, P, Q, learning_rate, lambda_reg, k)\u001b[0m\n\u001b[1;32m     74\u001b[0m q_fi \u001b[38;5;241m=\u001b[39m Q[f, item_idx]\n\u001b[1;32m     76\u001b[0m P[user_idx, f] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m (error \u001b[38;5;241m*\u001b[39m q_fi \u001b[38;5;241m-\u001b[39m lambda_reg \u001b[38;5;241m*\u001b[39m p_uf)\n\u001b[0;32m---> 77\u001b[0m Q[f, item_idx] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m (error \u001b[38;5;241m*\u001b[39m p_uf \u001b[38;5;241m-\u001b[39m lambda_reg \u001b[38;5;241m*\u001b[39m q_fi)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_rows = train.row\n",
    "train_cols = train.col\n",
    "train_data = train.data\n",
    "num_train_samples = len(train_data)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    shuffled_indices = list(range(num_train_samples))\n",
    "    random.shuffle(shuffled_indices)\n",
    "\n",
    "    for idx in shuffled_indices:\n",
    "        u = train_rows[idx]\n",
    "        i = train_cols[idx]\n",
    "        r_ui = train_data[idx]\n",
    "\n",
    "        predicted_r_ui = calculate_predicted_rating(\n",
    "            u, i, P, Q, user_bias, item_bias, global_average\n",
    "        )\n",
    "\n",
    "        error = calculate_error(r_ui, predicted_r_ui)\n",
    "\n",
    "        update_biases(u, i, error, user_bias, item_bias, learning_rate, lambda_reg)\n",
    "\n",
    "        update_latent_features(u, i, error, P, Q, learning_rate, lambda_reg, k)\n",
    "\n",
    "    if (epoch + 1) % log_step == 0:\n",
    "        train_sse = 0  # Sum of Squared Errors for the current epoch\n",
    "        # Iterate through all training samples again to calculate the total error\n",
    "        for idx in range(num_train_samples):\n",
    "            u = train_rows[idx]\n",
    "            i = train_cols[idx]\n",
    "            r_ui = train_data[idx]\n",
    "            # Calculate predicted rating using the *current* parameters\n",
    "            predicted_r_ui = calculate_predicted_rating(\n",
    "                u, i, P, Q, user_bias, item_bias, global_average\n",
    "            )\n",
    "            train_sse += (r_ui - predicted_r_ui) ** 2\n",
    "\n",
    "        train_rmse = np.sqrt(train_sse / num_train_samples)\n",
    "        test_rmse = calculate_rmse(P, Q, user_bias, item_bias, global_average, test)\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{num_epochs}, Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "print(\"\\nTraining finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test RMSE: 1.8369\n"
     ]
    }
   ],
   "source": [
    "def calculate_rmse(P, Q, user_bias, item_bias, global_average, test):\n",
    "    \"\"\"\n",
    "    Calculates the Root Mean Squared Error (RMSE) on a sparse matrix.\n",
    "\n",
    "    Args:\n",
    "        P (np.ndarray): Trained user latent feature matrix.\n",
    "        Q (np.ndarray): Trained item latent feature matrix.\n",
    "        user_bias (np.ndarray): Trained user bias vector.\n",
    "        item_bias (np.ndarray): Trained item bias vector.\n",
    "        global_average (float): Calculated global average rating.\n",
    "        test (matrix): The sparse matrix to evaluate on (e.g., test set).\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated RMSE.\n",
    "    \"\"\"\n",
    "\n",
    "    test_rows = test.row\n",
    "    test_cols = test.col\n",
    "    test_data = test.data\n",
    "    num_test_samples = len(test_data)\n",
    "\n",
    "    if num_test_samples == 0:\n",
    "        return 0.0  # Avoid division by zero\n",
    "\n",
    "    sse = 0  # Sum of Squared Errors\n",
    "    for idx in range(num_test_samples):\n",
    "        u = test_rows[idx]\n",
    "        i = test_cols[idx]\n",
    "        r_ui = test_data[idx]\n",
    "\n",
    "        # Predict rating\n",
    "        predicted_r_ui = (\n",
    "            global_average + user_bias[u] + item_bias[i] + np.dot(P[u, :], Q[:, i])\n",
    "        )\n",
    "\n",
    "        sse += (r_ui - predicted_r_ui) ** 2\n",
    "\n",
    "    rmse = np.sqrt(sse / num_test_samples)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "# Calculate RMSE on the test set\n",
    "test_rmse = calculate_rmse(P, Q, user_bias, item_bias, global_average, test)\n",
    "print(f\"\\nTest RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx = unique_user_ids[6]\n",
    "item_idx = 5\n",
    "\n",
    "try:\n",
    "    mapped_user_idx = np.where(unique_user_ids == user_idx)[0][0]\n",
    "    mapped_item_idx = unique_item_ids[item_idx]  # Get original item ID for mapped index\n",
    "    # Now find the mapped index for this original item ID\n",
    "    mapped_item_idx_for_prediction = np.where(unique_item_ids == mapped_item_idx)[0][0]\n",
    "\n",
    "    predicted_rating_example = calculate_predicted_rating(\n",
    "        mapped_user_idx,\n",
    "        mapped_item_idx_for_prediction,\n",
    "        P,\n",
    "        Q,\n",
    "        user_bias,\n",
    "        item_bias,\n",
    "        global_average,\n",
    "    )\n",
    "    print(\n",
    "        f\"\\nPredicted rating for original user ID {user_idx} (mapped index {mapped_user_idx}) and original item ID {item_idx} (mapped index {mapped_item_idx_for_prediction}): {predicted_rating_example:.4f}\"\n",
    "    )\n",
    "\n",
    "except IndexError:\n",
    "    print(\n",
    "        \"\\nCould not find mapped index for example prediction. Ensure original IDs exist in unique IDs.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell 6: Recommendation Function\n",
    "def get_recommendations(\n",
    "    original_user_id,\n",
    "    n,\n",
    "    P,\n",
    "    Q,\n",
    "    user_bias,\n",
    "    item_bias,\n",
    "    global_average,\n",
    "    train_matrix,\n",
    "    unique_user_ids,\n",
    "    unique_item_ids,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates top N recommendations for a given user.\n",
    "\n",
    "    Args:\n",
    "        original_user_id: The original ID of the user.\n",
    "        n (int): The number of recommendations to generate.\n",
    "        P (np.ndarray): Trained user latent feature matrix (num_users, k).\n",
    "        Q (np.ndarray): Trained item latent feature matrix (k, num_items).\n",
    "        user_bias (np.ndarray): Trained user bias vector (num_users,).\n",
    "        item_bias (np.ndarray): Trained item bias vector (num_items,).\n",
    "        global_average (float): Calculated global average rating.\n",
    "        train_matrix (matrix): The sparse training interaction matrix.\n",
    "        unique_user_ids (np.ndarray): Array mapping mapped user indices to original IDs.\n",
    "        unique_item_ids (np.ndarray): Array mapping mapped item indices to original IDs.\n",
    "\n",
    "    Returns:n_matrix\n",
    "        list: A list of tuples (original_item_id, predicted_rating) for the top N recommendations.\n",
    "              Returns an empty list if the user ID is not found.\n",
    "    \"\"\"\n",
    "    # Find the mapped index for the original user ID\n",
    "    try:\n",
    "        user_idx = np.where(unique_user_ids == original_user_id)[0][0]\n",
    "    except IndexError:\n",
    "        print(\n",
    "            f\"Warning: Original user ID {original_user_id} not found in unique user IDs.\"\n",
    "        )\n",
    "        return []  # Return empty list if user not found\n",
    "\n",
    "    num_items = Q.shape[1]\n",
    "    all_item_indices = np.arange(num_items)\n",
    "\n",
    "    # Find items the user has already rated in the training set\n",
    "    user_row_sparse = train_matrix.getrow(user_idx)\n",
    "    rated_item_indices = user_row_sparse.indices\n",
    "\n",
    "    # Find items the user has NOT rated\n",
    "    unrated_item_indices = np.setdiff1d(all_item_indices, rated_item_indices)\n",
    "\n",
    "    user_latent_features = P[user_idx, :]  # Shape (k,)\n",
    "    unrated_item_latent_features = Q[\n",
    "        :, unrated_item_indices\n",
    "    ]  # Shape (k, num_unrated_items)\n",
    "\n",
    "    # Calculate dot products: result is (num_unrated_items,)\n",
    "    latent_predictions = (\n",
    "        user_latent_features @ unrated_item_latent_features\n",
    "    )  # Using @ for matrix multiplication (1xk @ kxN -> 1xN)\n",
    "\n",
    "    predicted_ratings_for_user = (\n",
    "        global_average\n",
    "        + user_bias[user_idx]\n",
    "        + item_bias[unrated_item_indices]\n",
    "        + latent_predictions\n",
    "    )\n",
    "\n",
    "    # Get the indices of the top N predicted ratings within the unrated_item_indices array\n",
    "    top_n_indices_in_unrated = np.argsort(predicted_ratings_for_user)[::-1][:n]\n",
    "\n",
    "    # Get the mapped item indices of the top N recommended items\n",
    "    recommended_mapped_item_indices = unrated_item_indices[top_n_indices_in_unrated]\n",
    "\n",
    "    # Get the original item IDs and their predicted ratings\n",
    "    recommended_items_with_ratings = [\n",
    "        (unique_item_ids[item_idx], predicted_ratings_for_user[i])\n",
    "        for i, item_idx in enumerate(recommended_mapped_item_indices)\n",
    "    ]  # Use index 'i' from top_n_indices_in_unrated to get the correct predicted rating\n",
    "\n",
    "    return recommended_items_with_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_user_id_to_recommend = unique_user_ids[\n",
    "    6\n",
    "]  # Choose an original user ID that exists in unique_user_ids\n",
    "top_n_recommendations = 5\n",
    "\n",
    "recommendations = get_recommendations(\n",
    "    original_user_id_to_recommend,\n",
    "    top_n_recommendations,\n",
    "    P,\n",
    "    Q,\n",
    "    user_bias,\n",
    "    item_bias,\n",
    "    global_average,\n",
    "    train,\n",
    "    unique_user_ids,\n",
    "    unique_item_ids,\n",
    ")\n",
    "\n",
    "if recommendations:\n",
    "    print(\n",
    "        f\"\\nTop {top_n_recommendations} recommendations for original user ID {original_user_id_to_recommend}:\"\n",
    "    )\n",
    "    for item_id, predicted_rating in recommendations:\n",
    "        print(f\"  Item ID: {item_id}, Predicted Rating: {predicted_rating:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_user_id_to_recommend = (\n",
    "    12  # Choose an original user ID that exists in unique_user_ids\n",
    ")\n",
    "top_n_recommendations = 5\n",
    "\n",
    "recommendations = get_recommendations(\n",
    "    original_user_id_to_recommend,\n",
    "    top_n_recommendations,\n",
    "    P,\n",
    "    Q,\n",
    "    user_bias,\n",
    "    item_bias,\n",
    "    global_average,\n",
    "    train,\n",
    "    unique_user_ids,\n",
    "    unique_item_ids,\n",
    ")\n",
    "\n",
    "if recommendations:\n",
    "    print(\n",
    "        f\"\\nTop {top_n_recommendations} recommendations for original user ID {original_user_id_to_recommend}:\"\n",
    "    )\n",
    "    for item_id, predicted_rating in recommendations:\n",
    "        print(f\"  Item ID: {item_id}, Predicted Rating: {predicted_rating:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_users_idx = [\n",
    "    8,\n",
    "    9,\n",
    "    12,\n",
    "    14,\n",
    "    16,\n",
    "    17,\n",
    "    19,\n",
    "    22,\n",
    "    26,\n",
    "    32,\n",
    "    39,\n",
    "    42,\n",
    "    44,\n",
    "    51,\n",
    "    53,\n",
    "    56,\n",
    "    64,\n",
    "    67,\n",
    "    69,\n",
    "    70,\n",
    "]\n",
    "eval_top_n_recommendations = 10\n",
    "\n",
    "eval_recommendations = [\n",
    "    get_recommendations(\n",
    "        user_idx,\n",
    "        eval_top_n_recommendations,\n",
    "        P,\n",
    "        Q,\n",
    "        user_bias,\n",
    "        item_bias,\n",
    "        global_average,\n",
    "        train,\n",
    "        unique_user_ids,\n",
    "        unique_item_ids,\n",
    "    )\n",
    "    for user_idx in eval_users_idx\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
