{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# کلون کردن ریپوزیتوری\n",
        "!git clone https://github.com/Peiyance/TransGNN-torch.git\n",
        "\n",
        "# انتقال دایرکتوری Data به مسیر اصلی\n",
        "!mv /content/TransGNN-torch/Data /content/Data\n",
        "\n",
        "# بررسی وجود فایل‌ها\n",
        "!ls /content/Data\n",
        "!ls /content/Data/yelp\n",
        "!ls /content/Data/gowalla\n",
        "!ls /content/Data/tmall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQfhuK1Eh7Ok",
        "outputId": "fc062c55-e912-483a-f184-4f87863d98c3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TransGNN-torch'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Counting objects: 100% (101/101), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 101 (delta 18), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (101/101), 22.43 MiB | 4.55 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n",
            "gowalla  Readme.md  tmall  yelp\n",
            "item_list.txt  test.txt   trnMat.pkl  user_list.txt\n",
            "process.py     train.txt  tstMat.pkl\n",
            "item_list.txt  test.txt   trnMat.pkl  user_list.txt\n",
            "process.py     train.txt  tstMat.pkl\n",
            "tstMat.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gowalla  tmall  yelp\n",
        "item_list.txt  process.py  test.txt  train.txt  trnMat.pkl  tstMat.pkl  user_list.txt  # برای yelp و gowalla\n",
        "tstMat.pkl  # برای tmall"
      ],
      "metadata": {
        "id": "9Xjx3cYXiUPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# نصب پکیج‌های مورد نیاز\n",
        "!pip install torch torch-geometric setproctitle\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "import argparse\n",
        "import pickle\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "from scipy.sparse import csr_matrix, coo_matrix, dok_matrix\n",
        "import torch_geometric.nn as pygnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zmaGArQd_9x",
        "outputId": "7d58099c-842e-4f0e-b1c7-f8d3a377fdce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.6-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.12.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.8.3)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.6-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Installing collected packages: setproctitle, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, torch-geometric, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 setproctitle-1.3.6 torch-geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تعریف آرگومان‌ها\n",
        "def ParseArgs():\n",
        "    parser = argparse.ArgumentParser(description='Model Params')\n",
        "    parser.add_argument('--lr', default=1e-3, type=float, help='learning rate')\n",
        "    parser.add_argument('--batch', default=4096, type=int, help='batch size')\n",
        "    parser.add_argument('--leaky', default=0.5, type=float, help='slope of leaky relu')\n",
        "    parser.add_argument('--tstBat', default=64, type=int, help='number of users in a testing batch')\n",
        "    parser.add_argument('--epoch', default=40, type=int, help='number of epochs')\n",
        "    parser.add_argument('--decay', default=1, type=float, help='weight decay rate')\n",
        "    parser.add_argument('--save_path', default='tem', help='file name to save model and training record')\n",
        "    parser.add_argument('--latdim', default=32, type=int, help='embedding size')\n",
        "    parser.add_argument('--hyperNum', default=128, type=int, help='number of hyperedges')\n",
        "    parser.add_argument('--gnn_layer', default=2, type=int, help='number of gnn layers')\n",
        "    parser.add_argument('--load_model', default=None, help='model name to load')\n",
        "    parser.add_argument('--topk', default=20, type=int, help='K of top K')\n",
        "    parser.add_argument('--att_head', default=2, type=int, help='number of attention heads')\n",
        "    parser.add_argument('--keepRate', default=0.5, type=float, help='ratio of edges to keep')\n",
        "    parser.add_argument('--temp', default=0.2, type=float, help='temperature')\n",
        "    parser.add_argument('--block_num', default=2, type=int, help='number of hops in gcn precessing')\n",
        "    parser.add_argument('--mult', default=1, type=float, help='multiplication factor')\n",
        "    parser.add_argument('--data', default='yelp', type=str, help='name of dataset')\n",
        "    parser.add_argument('--tstEpoch', default=3, type=int, help='number of epoch to test while training')\n",
        "    parser.add_argument('--gpu', default='0', type=str, help='indicates which gpu to use')\n",
        "    parser.add_argument('--edgeSampRate', default=0.1, type=float, help='Ratio of sampled edges')\n",
        "    parser.add_argument('--dropout', default=0, type=float, help='Ratio of transformer layer dropout')\n",
        "    parser.add_argument('--num_head', default=4, type=int, help='Multihead number of transformer layer')\n",
        "    return parser.parse_args(args=[])  # برای کولب، از args=[] استفاده می‌کنیم\n",
        "\n",
        "args = ParseArgs()"
      ],
      "metadata": {
        "id": "Rz5na9SseDXc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ماژول TimeLogger\n",
        "logmsg = ''\n",
        "timemark = dict()\n",
        "saveDefault = True\n",
        "\n",
        "def log(msg, save=None, oneline=False):\n",
        "    global logmsg\n",
        "    global saveDefault\n",
        "    time = datetime.datetime.now()\n",
        "    tem = '%s: %s' % (time, msg)\n",
        "    if save is not None:\n",
        "        if save:\n",
        "            logmsg += tem + '\\n'\n",
        "    elif saveDefault:\n",
        "        logmsg += tem + '\\n'\n",
        "    if oneline:\n",
        "        print(tem, end='\\r')\n",
        "    else:\n",
        "        print(tem)\n",
        "\n",
        "def marktime(marker):\n",
        "    global timemark\n",
        "    timemark[marker] = datetime.datetime.now()\n"
      ],
      "metadata": {
        "id": "WiVNr_53eHxP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ماژول Utils\n",
        "def innerProduct(usrEmbeds, itmEmbeds):\n",
        "    return torch.sum(usrEmbeds * itmEmbeds, dim=-1)\n",
        "\n",
        "def pairPredict(ancEmbeds, posEmbeds, negEmbeds):\n",
        "    return innerProduct(ancEmbeds, posEmbeds) - innerProduct(ancEmbeds, negEmbeds)\n",
        "\n",
        "def calcRegLoss(model):\n",
        "    ret = 0\n",
        "    for W in model.parameters():\n",
        "        ret += W.norm(2).square()\n",
        "    return ret\n",
        "\n",
        "def contrastLoss(embeds1, embeds2, nodes, temp):\n",
        "    embeds1 = F.normalize(embeds1 + 1e-8, p=2)\n",
        "    embeds2 = F.normalize(embeds2 + 1e-8, p=2)\n",
        "    pckEmbeds1 = embeds1[nodes]\n",
        "    pckEmbeds2 = embeds2[nodes]\n",
        "    nume = torch.exp(torch.sum(pckEmbeds1 * pckEmbeds2, dim=-1) / temp)\n",
        "    deno = torch.exp(pckEmbeds1 @ embeds2.T / temp).sum(-1) + 1e-8\n",
        "    return -torch.log(nume / deno).mean()"
      ],
      "metadata": {
        "id": "4kSWLUs2eLGW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ماژول Transformer\n",
        "def padding_mask(seq):\n",
        "    length = seq.shape[1]\n",
        "    mask = seq.eq(0)\n",
        "    mask = mask.unsqueeze(1).expand(-1, length, -1)\n",
        "    return mask\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads=8, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "        d_ff = d_ff or 4 * d_model\n",
        "        self.attention = nn.MultiheadAttention(d_model, num_heads, dropout=dropout)\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = getattr(F, activation)\n",
        "\n",
        "    def forward(self, x, attn_mask=None, length_mask=None):\n",
        "        N = x.shape[0]\n",
        "        L = x.shape[1]\n",
        "\n",
        "        attn_output, _ = self.attention(\n",
        "            x, x, x,\n",
        "            key_padding_mask=attn_mask\n",
        "        )\n",
        "\n",
        "        x = x + self.dropout(attn_output)\n",
        "        y = x = self.norm1(x)\n",
        "        y = self.dropout(self.activation(self.linear1(y)))\n",
        "        y = self.dropout(self.linear2(y))\n",
        "\n",
        "        return self.norm2(x + y)\n",
        "\n",
        "class Encoder_Layer(nn.Module):\n",
        "    def __init__(self, embedding_dim=128, hidden_dim=64, num_heads=8, dropout=0):\n",
        "        super(Encoder_Layer, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.calculate_q = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
        "        torch.nn.init.xavier_normal_(self.calculate_q.weight, gain=1)\n",
        "        self.calculate_k = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
        "        torch.nn.init.xavier_normal_(self.calculate_k.weight, gain=1)\n",
        "        self.calculate_v = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
        "        torch.nn.init.xavier_normal_(self.calculate_v.weight, gain=1)\n",
        "        self.MultiheadAttention = nn.MultiheadAttention(self.embedding_dim, num_heads, dropout=dropout)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "        self.fc = nn.Linear(embedding_dim, hidden_dim)\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        torch.nn.init.xavier_normal_(self.fc1.weight, gain=1)\n",
        "\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        torch.nn.init.xavier_normal_(self.fc2.weight, gain=1)\n",
        "\n",
        "        self.dropout2 = nn.Dropout(p=dropout)\n",
        "        self.layer_norm2 = nn.LayerNorm(hidden_dim)\n",
        "        self.relu2 = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, querys, keys, values, mask=None):\n",
        "        query = self.calculate_q(querys).transpose(0, 1).contiguous()\n",
        "        key = self.calculate_k(keys).transpose(0, 1).contiguous()\n",
        "        value = self.calculate_v(values).transpose(0, 1).contiguous()\n",
        "\n",
        "        output, _ = self.MultiheadAttention(query, key, value, key_padding_mask=mask)\n",
        "        output = output.transpose(0, 1).contiguous()\n",
        "\n",
        "        output = querys + self.dropout(output)\n",
        "        output = self.layer_norm(output)\n",
        "\n",
        "        output = self.fc(output)\n",
        "        tmp = output\n",
        "\n",
        "        output = self.fc2(self.dropout2(self.relu2(self.fc1(output))))\n",
        "        output = tmp + self.dropout2(output)\n",
        "        output = self.layer_norm2(output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "xo9fzd2ZeRkR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# مدل TransGNN\n",
        "class TransGNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TransGNN, self).__init__()\n",
        "        self.user_embeding = nn.Parameter(nn.init.xavier_uniform_(torch.empty(args.user, args.latdim)))\n",
        "        self.item_embeding = nn.Parameter(nn.init.xavier_uniform_(torch.empty(args.item, args.latdim)))\n",
        "        self.user_transformer_encoder = TransformerEncoderLayer(d_model=args.latdim, num_heads=args.num_head, dropout=args.dropout)\n",
        "        self.item_transformer_encoder = TransformerEncoderLayer(d_model=args.latdim, num_heads=args.num_head, dropout=args.dropout)\n",
        "\n",
        "    def user_transformer_layer(self, embeds, mask=None):\n",
        "        assert len(embeds.shape) <= 3, f\"Shape Error, embed shape is {embeds.shape}, out of size!\"\n",
        "        if len(embeds.shape) == 2:\n",
        "            embeds = embeds.unsqueeze(dim=0)\n",
        "            embeds = self.user_transformer_encoder(embeds, mask)\n",
        "            embeds = embeds.squeeze()\n",
        "        else:\n",
        "            embeds = self.user_transformer_encoder(embeds, mask)\n",
        "        return embeds\n",
        "\n",
        "    def item_transformer_layer(self, embeds, mask=None):\n",
        "        assert len(embeds.shape) <= 3, f\"Shape Error, embed shape is {embeds.shape}, out of size!\"\n",
        "        if len(embeds.shape) == 2:\n",
        "            embeds = embeds.unsqueeze(dim=0)\n",
        "            embeds = self.item_transformer_encoder(embeds, mask)\n",
        "            embeds = embeds.squeeze()\n",
        "        else:\n",
        "            embeds = self.item_transformer_encoder(embeds, mask)\n",
        "        return embeds\n",
        "\n",
        "    def gnn_message_passing(self, adj, embeds):\n",
        "        return torch.spmm(adj, embeds)\n",
        "\n",
        "    def forward(self, adj):\n",
        "        embeds = [torch.concat([self.user_embeding, self.item_embeding], dim=0)]\n",
        "        for i in range(args.block_num):\n",
        "            tmp_embeds = self.gnn_message_passing(adj, embeds[-1])\n",
        "            tmp_user_embeds = tmp_embeds[:args.user]\n",
        "            tmp_item_embeds = tmp_embeds[args.user:]\n",
        "            tmp_user_embeds = self.user_transformer_layer(tmp_user_embeds)\n",
        "            tmp_item_embeds = self.item_transformer_layer(tmp_item_embeds)\n",
        "\n",
        "            tmp_user_embeds += tmp_embeds[:args.user]\n",
        "            tmp_item_embeds += tmp_embeds[args.user:]\n",
        "\n",
        "            tmp_embeds = torch.concat([tmp_user_embeds, tmp_item_embeds], dim=0)\n",
        "            embeds.append(tmp_embeds)\n",
        "\n",
        "        embeds = sum(embeds)\n",
        "        user_embeds = embeds[:args.user]\n",
        "        item_embeds = embeds[args.user:]\n",
        "        return embeds, user_embeds, item_embeds\n",
        "\n",
        "    def pickEdges(self, adj):\n",
        "        idx = adj._indices()\n",
        "        rows, cols = idx[0, :], idx[1, :]\n",
        "        mask = torch.logical_and(rows <= args.user, cols > args.user)\n",
        "        rows, cols = rows[mask], cols[mask]\n",
        "        edgeSampNum = int(args.edgeSampRate * rows.shape[0])\n",
        "        if edgeSampNum % 2 == 1:\n",
        "            edgeSampNum += 1\n",
        "        edgeids = torch.randint(rows.shape[0], [edgeSampNum])\n",
        "        pckUsrs, pckItms = rows[edgeids], cols[edgeids] - args.user\n",
        "        return pckUsrs, pckItms\n",
        "\n",
        "    def pickRandomEdges(self, adj):\n",
        "        edgeNum = adj._indices().shape[1]\n",
        "        edgeSampNum = int(args.edgeSampRate * edgeNum)\n",
        "        if edgeSampNum % 2 == 1:\n",
        "            edgeSampNum += 1\n",
        "        rows = torch.randint(args.user, [edgeSampNum])\n",
        "        cols = torch.randint(args.item, [edgeSampNum])\n",
        "        return rows, cols\n",
        "\n",
        "    def bprLoss(self, user_embeding, item_embeding, ancs, poss, negs):\n",
        "        ancEmbeds = user_embeding[ancs]\n",
        "        posEmbeds = item_embeding[poss]\n",
        "        negEmbeds = item_embeding[negs]\n",
        "        scoreDiff = pairPredict(ancEmbeds, posEmbeds, negEmbeds)\n",
        "        bprLoss = - ((scoreDiff).sigmoid() + 1e-6).log().mean()\n",
        "        return bprLoss\n",
        "\n",
        "    def calcLosses(self, ancs, poss, negs, adj):\n",
        "        embeds, user_embeds, item_embeds = self.forward(adj)\n",
        "        user_embeding, item_embeding = embeds[:args.user], embeds[args.user:]\n",
        "        bprLoss = self.bprLoss(user_embeding, item_embeding, ancs, poss, negs) + self.bprLoss(user_embeds, item_embeds, ancs, poss, negs)\n",
        "        return bprLoss\n",
        "\n",
        "    def predict(self, adj):\n",
        "        embeds, user_embeds, item_embeds = self.forward(adj)\n",
        "        return user_embeds, item_embeds"
      ],
      "metadata": {
        "id": "o7CqvPWqeVLi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# کلاس DataHandler\n",
        "class DataHandler:\n",
        "    def __init__(self):\n",
        "        if args.data == 'yelp':\n",
        "            predir = 'Data/yelp/'\n",
        "        elif args.data == 'ml10m':\n",
        "            predir = 'Data/ml10m/'\n",
        "        elif args.data == 'tmall':\n",
        "            predir = 'Data/tmall/'\n",
        "        elif args.data == 'gowalla':\n",
        "            predir = 'Data/gowalla/'\n",
        "        elif args.data == 'amazon-book':\n",
        "            predir = 'Data/amazon-book/'\n",
        "        self.predir = predir\n",
        "        self.trnfile = predir + 'trnMat.pkl'\n",
        "        self.tstfile = predir + 'tstMat.pkl'\n",
        "\n",
        "    def loadOneFile(self, filename):\n",
        "        with open(filename, 'rb') as fs:\n",
        "            ret = (pickle.load(fs) != 0).astype(np.float32)\n",
        "        if type(ret) != coo_matrix:\n",
        "            ret = sp.coo_matrix(ret)\n",
        "        return ret\n",
        "\n",
        "    def normalizeAdj(self, mat):\n",
        "        degree = np.array(mat.sum(axis=-1))\n",
        "        dInvSqrt = np.reshape(np.power(degree, -0.5), [-1])\n",
        "        dInvSqrt[np.isinf(dInvSqrt)] = 0.0\n",
        "        dInvSqrtMat = sp.diags(dInvSqrt)\n",
        "        return mat.dot(dInvSqrtMat).transpose().dot(dInvSqrtMat).tocoo()\n",
        "\n",
        "    def makeTorchAdj(self, mat):\n",
        "        a = sp.csr_matrix((args.user, args.user))\n",
        "        b = sp.csr_matrix((args.item, args.item))\n",
        "        mat = sp.vstack([sp.hstack([a, mat]), sp.hstack([mat.transpose(), b])])\n",
        "        mat = (mat != 0) * 1.0\n",
        "        mat = self.normalizeAdj(mat)\n",
        "        idxs = torch.from_numpy(np.vstack([mat.row, mat.col]).astype(np.int64))\n",
        "        vals = torch.from_numpy(mat.data.astype(np.float32))\n",
        "        shape = torch.Size(mat.shape)\n",
        "        return torch.sparse.FloatTensor(idxs, vals, shape).cuda()\n",
        "\n",
        "    def makeSample(self):\n",
        "        user_sample_idx = torch.tensor([[args.user + i for i in range(args.item)] * args.user])\n",
        "        item_sample_idx = torch.tensor([[i for i in range(args.user)] * args.item])\n",
        "        return user_sample_idx, item_sample_idx\n",
        "\n",
        "    def makeMask(self):\n",
        "        u_u_mask = torch.zeros(size=(args.user, args.user), dtype=bool)\n",
        "        u_i_mask = torch.ones(size=(args.user, args.item), dtype=bool)\n",
        "        i_i_mask = torch.zeros(size=(args.item, args.item), dtype=bool)\n",
        "        i_u_mask = torch.ones(size=(args.item, args.user), dtype=bool)\n",
        "        u_mask = torch.concat([u_u_mask, u_i_mask], dim=-1)\n",
        "        i_mask = torch.concat([i_u_mask, i_i_mask], dim=-1)\n",
        "        mask = torch.concat([u_mask, i_mask], dim=0)\n",
        "        return mask\n",
        "\n",
        "    def LoadData(self):\n",
        "        trnMat = self.loadOneFile(self.trnfile)\n",
        "        tstMat = self.loadOneFile(self.tstfile)\n",
        "        args.user, args.item = trnMat.shape\n",
        "        self.torchBiAdj = self.makeTorchAdj(trnMat)\n",
        "        self.mask = self.makeMask()\n",
        "        trnData = TrnData(trnMat)\n",
        "        self.trnLoader = data.DataLoader(trnData, batch_size=args.batch, shuffle=True, num_workers=0)\n",
        "        tstData = TstData(tstMat, trnMat)\n",
        "        self.tstLoader = data.DataLoader(tstData, batch_size=args.tstBat, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "4eam5-JReddn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# کلاس‌های Dataset\n",
        "class TrnData(data.Dataset):\n",
        "    def __init__(self, coomat):\n",
        "        self.rows = coomat.row\n",
        "        self.cols = coomat.col\n",
        "        self.dokmat = coomat.todok()\n",
        "        self.negs = np.zeros(len(self.rows)).astype(np.int32)\n",
        "\n",
        "    def negSampling(self):\n",
        "        for i in range(len(self.rows)):\n",
        "            u = self.rows[i]\n",
        "            while True:\n",
        "                iNeg = np.random.randint(args.item)\n",
        "                if (u, iNeg) not in self.dokmat:\n",
        "                    break\n",
        "            self.negs[i] = iNeg\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.rows)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.rows[idx], self.cols[idx], self.negs[idx]\n",
        "\n",
        "class TstData(data.Dataset):\n",
        "    def __init__(self, coomat, trnMat):\n",
        "        self.csrmat = (trnMat.tocsr() != 0) * 1.0\n",
        "        tstLocs = [None] * coomat.shape[0]\n",
        "        tstUsrs = set()\n",
        "        for i in range(len(coomat.data)):\n",
        "            row = coomat.row[i]\n",
        "            col = coomat.col[i]\n",
        "            if tstLocs[row] is None:\n",
        "                tstLocs[row] = list()\n",
        "            tstLocs[row].append(col)\n",
        "            tstUsrs.add(row)\n",
        "        tstUsrs = np.array(list(tstUsrs))\n",
        "        self.tstUsrs = tstUsrs\n",
        "        self.tstLocs = tstLocs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tstUsrs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.tstUsrs[idx], np.reshape(self.csrmat[self.tstUsrs[idx]].toarray(), [-1])"
      ],
      "metadata": {
        "id": "xNtLjbbneny4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# کلاس Coach\n",
        "class Coach:\n",
        "    def __init__(self, handler):\n",
        "        self.handler = handler\n",
        "        print('USER', args.user, 'ITEM', args.item)\n",
        "        print('NUM OF INTERACTIONS', self.handler.trnLoader.dataset.__len__())\n",
        "        self.metrics = dict()\n",
        "        mets = ['Loss', 'preLoss', 'Recall', 'NDCG']\n",
        "        for met in mets:\n",
        "            self.metrics['Train' + met] = list()\n",
        "            self.metrics['Test' + met] = list()\n",
        "\n",
        "    def makePrint(self, name, ep, reses, save):\n",
        "        ret = 'Epoch %d/%d, %s: ' % (ep, args.epoch, name)\n",
        "        for metric in reses:\n",
        "            val = reses[metric]\n",
        "            ret += '%s = %.4f, ' % (metric, val)\n",
        "            tem = name + metric\n",
        "            if save and tem in self.metrics:\n",
        "                self.metrics[tem].append(val)\n",
        "        ret = ret[:-2] + '  '\n",
        "        return ret\n",
        "\n",
        "    def run(self):\n",
        "        self.prepareModel()\n",
        "        log('Model Prepared')\n",
        "        if args.load_model is not None:\n",
        "            self.loadModel()\n",
        "            stloc = len(self.metrics['TrainLoss']) * args.tstEpoch - (args.tstEpoch - 1)\n",
        "        else:\n",
        "            stloc = 0\n",
        "            log('Model Initialized')\n",
        "        for ep in range(stloc, args.epoch):\n",
        "            tstFlag = (ep % args.tstEpoch == 0)\n",
        "            reses = self.trainEpoch()\n",
        "            log(self.makePrint('Train', ep, reses, tstFlag))\n",
        "            if tstFlag:\n",
        "                reses = self.testEpoch()\n",
        "                log(self.makePrint('Test', ep, reses, tstFlag))\n",
        "                self.saveHistory()\n",
        "            print()\n",
        "        reses = self.testEpoch()\n",
        "        log(self.makePrint('Test', args.epoch, reses, True))\n",
        "        self.saveHistory()\n",
        "\n",
        "    def prepareModel(self):\n",
        "        self.model = TransGNN().cuda()\n",
        "        self.opt = torch.optim.Adam(self.model.parameters(), lr=args.lr, weight_decay=0)\n",
        "\n",
        "    def trainEpoch(self):\n",
        "        trnLoader = self.handler.trnLoader\n",
        "        trnLoader.dataset.negSampling()\n",
        "        epLoss, epPreLoss = 0, 0\n",
        "        steps = trnLoader.dataset.__len__() // args.batch\n",
        "        for i, tem in enumerate(trnLoader):\n",
        "            ancs, poss, negs = tem\n",
        "            ancs = ancs.long().cuda()\n",
        "            poss = poss.long().cuda()\n",
        "            negs = negs.long().cuda()\n",
        "            bprLoss = self.model.calcLosses(ancs, poss, negs, self.handler.torchBiAdj)\n",
        "            loss = bprLoss\n",
        "            epLoss += loss.item()\n",
        "            epPreLoss += bprLoss.item()\n",
        "            self.opt.zero_grad()\n",
        "            loss.backward()\n",
        "            self.opt.step()\n",
        "            log('Step %d/%d: loss = %.3f         ' % (i, steps, loss), save=False, oneline=True)\n",
        "        ret = dict()\n",
        "        ret['Loss'] = epLoss / steps\n",
        "        ret['preLoss'] = epPreLoss / steps\n",
        "        return ret\n",
        "\n",
        "    def testEpoch(self):\n",
        "        tstLoader = self.handler.tstLoader\n",
        "        epLoss, epRecall, epNdcg = [0] * 3\n",
        "        i = 0\n",
        "        num = tstLoader.dataset.__len__()\n",
        "        steps = num // args.tstBat\n",
        "        for usr, trnMask in tstLoader:\n",
        "            i += 1\n",
        "            usr = usr.long().cuda()\n",
        "            trnMask = trnMask.cuda()\n",
        "            usrEmbeds, itmEmbeds = self.model.predict(self.handler.torchBiAdj)\n",
        "            allPreds = torch.mm(usrEmbeds[usr], torch.transpose(itmEmbeds, 1, 0)) * (1 - trnMask) - trnMask * 1e8\n",
        "            _, topLocs = torch.topk(allPreds, args.topk)\n",
        "            recall, ndcg = self.calcRes(topLocs.cpu().numpy(), self.handler.tstLoader.dataset.tstLocs, usr)\n",
        "            epRecall += recall\n",
        "            epNdcg += ndcg\n",
        "            log('Steps %d/%d: recall = %.2f, ndcg = %.2f          ' % (i, steps, recall, ndcg), save=False, oneline=True)\n",
        "        ret = dict()\n",
        "        ret['Recall'] = epRecall / num\n",
        "        ret['NDCG'] = epNdcg / num\n",
        "        return ret\n",
        "\n",
        "    def calcRes(self, topLocs, tstLocs, batIds):\n",
        "        assert topLocs.shape[0] == len(batIds)\n",
        "        allRecall = allNdcg = 0\n",
        "        for i in range(len(batIds)):\n",
        "            temTopLocs = list(topLocs[i])\n",
        "            temTstLocs = tstLocs[batIds[i]]\n",
        "            tstNum = len(temTstLocs)\n",
        "            maxDcg = np.sum([np.reciprocal(np.log2(loc + 2)) for loc in range(min(tstNum, args.topk))])\n",
        "            recall = dcg = 0\n",
        "            for val in temTstLocs:\n",
        "                if val in temTopLocs:\n",
        "                    recall += 1\n",
        "                    dcg += np.reciprocal(np.log2(temTopLocs.index(val) + 2))\n",
        "            recall = recall / tstNum\n",
        "            ndcg = dcg / maxDcg\n",
        "            allRecall += recall\n",
        "            allNdcg += ndcg\n",
        "        return allRecall, allNdcg\n",
        "\n",
        "    def saveHistory(self):\n",
        "        if args.epoch == 0:\n",
        "            return\n",
        "        os.makedirs('History', exist_ok=True)\n",
        "        with open('History/' + args.save_path + '.his', 'wb') as fs:\n",
        "            pickle.dump(self.metrics, fs)\n",
        "        os.makedirs('Models', exist_ok=True)\n",
        "        content = {'model': self.model}\n",
        "        torch.save(content, 'Models/' + args.save_path + '.mod')\n",
        "        log('Model Saved: %s' % args.save_path)\n",
        "\n",
        "    def loadModel(self):\n",
        "        ckp = torch.load('Models/' + args.load_model + '.mod')\n",
        "        self.model = ckp['model']\n",
        "        self.opt = torch.optim.Adam(self.model.parameters(), lr=args.lr, weight_decay=0)\n",
        "        with open('History/' + args.load_model + '.his', 'rb') as fs:\n",
        "            self.metrics = pickle.load(fs)\n",
        "        log('Model Loaded')"
      ],
      "metadata": {
        "id": "th4GCQCKesSn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# اجرای اصلی\n",
        "if __name__ == '__main__':\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
        "    import setproctitle\n",
        "    setproctitle.setproctitle('proc_title')\n",
        "\n",
        "    log('Start')\n",
        "    handler = DataHandler()\n",
        "    handler.LoadData()\n",
        "    log('Load Data')\n",
        "    coach = Coach(handler)\n",
        "    coach.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URsIpIu1d-M8",
        "outputId": "ae2f140f-cb5f-4c64-8b92-6fd0d72819ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-19 07:57:30.888912: Start\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-5a515d09767f>:20: DeprecationWarning: Please import `coo_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.coo` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
            "  ret = (pickle.load(fs) != 0).astype(np.float32)\n",
            "<ipython-input-9-5a515d09767f>:20: DeprecationWarning: numpy.core._multiarray_umath is deprecated and has been renamed to numpy._core._multiarray_umath. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core._multiarray_umath._reconstruct.\n",
            "  ret = (pickle.load(fs) != 0).astype(np.float32)\n",
            "<ipython-input-9-5a515d09767f>:41: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:644.)\n",
            "  return torch.sparse.FloatTensor(idxs, vals, shape).cuda()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-19 07:57:39.913322: Load Data\n",
            "USER 29601 ITEM 24734\n",
            "NUM OF INTERACTIONS 1069128\n",
            "2025-05-19 07:57:39.930747: Model Prepared\n",
            "2025-05-19 07:57:39.930778: Model Initialized\n",
            "2025-05-19 07:58:09.199556: Epoch 0/40, Train: Loss = 0.3216, preLoss = 0.3216  \n",
            "2025-05-19 07:58:34.295860: Epoch 0/40, Test: Recall = 0.0646, NDCG = 0.0530  \n",
            "2025-05-19 07:58:34.314567: Model Saved: tem\n",
            "\n",
            "2025-05-19 07:59:04.071486: Epoch 1/40, Train: Loss = 0.1681, preLoss = 0.1681  \n",
            "\n",
            "2025-05-19 07:59:32.806635: Epoch 2/40, Train: Loss = 0.1442, preLoss = 0.1442  \n",
            "\n",
            "2025-05-19 08:00:02.504283: Epoch 3/40, Train: Loss = 0.1317, preLoss = 0.1317  \n",
            "2025-05-19 08:00:27.655218: Epoch 3/40, Test: Recall = 0.0762, NDCG = 0.0651  \n",
            "2025-05-19 08:00:27.672751: Model Saved: tem\n",
            "\n",
            "2025-05-19 08:00:56.509420: Epoch 4/40, Train: Loss = 0.1191, preLoss = 0.1191  \n",
            "\n",
            "2025-05-19 08:01:25.474755: Epoch 5/40, Train: Loss = 0.1125, preLoss = 0.1125  \n",
            "\n",
            "2025-05-19 08:01:55.329123: Epoch 6/40, Train: Loss = 0.1095, preLoss = 0.1095  \n",
            "2025-05-19 08:02:20.504002: Epoch 6/40, Test: Recall = 0.0731, NDCG = 0.0621  \n",
            "2025-05-19 08:02:20.517550: Model Saved: tem\n",
            "\n",
            "2025-05-19 08:02:49.283615: Epoch 7/40, Train: Loss = 0.1044, preLoss = 0.1044  \n",
            "\n",
            "2025-05-19 08:03:18.979767: Epoch 8/40, Train: Loss = 0.1003, preLoss = 0.1003  \n",
            "\n",
            "2025-05-19 08:03:47.918008: Epoch 9/40, Train: Loss = 0.0960, preLoss = 0.0960  \n",
            "2025-05-19 08:04:12.976921: Epoch 9/40, Test: Recall = 0.0751, NDCG = 0.0637  \n",
            "2025-05-19 08:04:12.991493: Model Saved: tem\n",
            "\n",
            "2025-05-19 08:04:42.028891: Epoch 10/40, Train: Loss = 0.0936, preLoss = 0.0936  \n",
            "\n",
            "2025-05-19 08:05:11.392064: Epoch 11/40, Train: Loss = 0.0920, preLoss = 0.0920  \n",
            "\n",
            "2025-05-19 08:05:40.236226: Epoch 12/40, Train: Loss = 0.0890, preLoss = 0.0890  \n",
            "2025-05-19 08:06:05.273881: Epoch 12/40, Test: Recall = 0.0737, NDCG = 0.0636  \n",
            "2025-05-19 08:06:05.290677: Model Saved: tem\n",
            "\n",
            "2025-05-19 08:06:35.132604: Epoch 13/40, Train: Loss = 0.0878, preLoss = 0.0878  \n",
            "\n",
            "2025-05-19 08:07:04.075541: Epoch 14/40, Train: Loss = 0.0901, preLoss = 0.0901  \n",
            "\n",
            "2025-05-19 08:07:33.012949: Epoch 15/40, Train: Loss = 0.0850, preLoss = 0.0850  \n",
            "2025-05-19 08:07:58.272911: Epoch 15/40, Test: Recall = 0.0721, NDCG = 0.0611  \n",
            "2025-05-19 08:07:58.299242: Model Saved: tem\n",
            "\n",
            "2025-05-19 08:08:27.395517: Epoch 16/40, Train: Loss = 0.0831, preLoss = 0.0831  \n",
            "\n",
            "2025-05-19 08:08:56.189558: Epoch 17/40, Train: Loss = 0.0828, preLoss = 0.0828  \n",
            "\n",
            "2025-05-19 08:09:26.312678: Epoch 18/40, Train: Loss = 0.0835, preLoss = 0.0835  \n",
            "2025-05-19 08:09:51.431220: Epoch 18/40, Test: Recall = 0.0711, NDCG = 0.0608  \n",
            "2025-05-19 08:09:51.447697: Model Saved: tem\n",
            "\n",
            "2025-05-19 08:10:20.190770: Epoch 19/40, Train: Loss = 0.0817, preLoss = 0.0817  \n",
            "\n",
            "2025-05-19 08:10:49.719423: Epoch 20/40, Train: Loss = 0.0838, preLoss = 0.0838  \n",
            "\n",
            "2025-05-19 08:11:18.568700: Epoch 21/40, Train: Loss = 0.0816, preLoss = 0.0816  \n",
            "2025-05-19 08:11:43.683052: Epoch 21/40, Test: Recall = 0.0718, NDCG = 0.0613  \n",
            "2025-05-19 08:11:43.698995: Model Saved: tem\n",
            "\n",
            "2025-05-19 08:12:12.588409: Epoch 22/40, Train: Loss = 0.0799, preLoss = 0.0799  \n",
            "\n",
            "2025-05-19 08:12:42.183652: Epoch 23/40, Train: Loss = 0.0783, preLoss = 0.0783  \n",
            "\n",
            "2025-05-19 08:13:11.068668: Epoch 24/40, Train: Loss = 0.0783, preLoss = 0.0783  \n",
            "2025-05-19 08:13:36.296594: Epoch 24/40, Test: Recall = 0.0713, NDCG = 0.0608  \n",
            "2025-05-19 08:13:36.319484: Model Saved: tem\n",
            "\n",
            "2025-05-19 08:14:06.257589: Epoch 25/40, Train: Loss = 0.0759, preLoss = 0.0759  \n",
            "\n",
            "2025-05-19 08:14:35.222365: Epoch 26/40, Train: Loss = 0.0767, preLoss = 0.0767  \n",
            "\n",
            "2025-05-19 08:15:04.281165: Epoch 27/40, Train: Loss = 0.0764, preLoss = 0.0764  \n",
            "2025-05-19 08:15:29.715320: Epoch 27/40, Test: Recall = 0.0730, NDCG = 0.0626  \n",
            "2025-05-19 08:15:29.745866: Model Saved: tem\n",
            "\n",
            "2025-05-19 08:15:58.926021: Epoch 28/40, Train: Loss = 0.0758, preLoss = 0.0758  \n",
            "\n",
            "2025-05-19 08:16:27.953237: Epoch 29/40, Train: Loss = 0.0760, preLoss = 0.0760  \n",
            "\n",
            "2025-05-19 08:16:57.664108: Epoch 30/40, Train: Loss = 0.0753, preLoss = 0.0753  \n",
            "2025-05-19 08:17:22.971097: Epoch 30/40, Test: Recall = 0.0731, NDCG = 0.0631  \n",
            "2025-05-19 08:17:22.988445: Model Saved: tem\n",
            "\n",
            "2025-05-19 08:17:52.123979: Epoch 31/40, Train: Loss = 0.0738, preLoss = 0.0738  \n",
            "\n",
            "2025-05-19 08:18:21.473290: Epoch 32/40, Train: Loss = 0.0734, preLoss = 0.0734  \n",
            "\n",
            "2025-05-19 08:18:50.566482: Epoch 33/40, Train: Loss = 0.0727, preLoss = 0.0727  \n",
            "2025-05-19 08:19:15.675393: Epoch 33/40, Test: Recall = 0.0696, NDCG = 0.0590  \n",
            "2025-05-19 08:19:15.691841: Model Saved: tem\n",
            "\n",
            "2025-05-19 08:19:44.330733: Epoch 34/40, Train: Loss = 0.0727, preLoss = 0.0727  \n",
            "\n",
            "2025-05-19 08:20:14.172658: Epoch 35/40, Train: Loss = 0.0716, preLoss = 0.0716  \n",
            "\n",
            "2025-05-19 08:20:43.064756: Epoch 36/40, Train: Loss = 0.0710, preLoss = 0.0710  \n",
            "2025-05-19 08:21:08.387392: Epoch 36/40, Test: Recall = 0.0713, NDCG = 0.0612  \n",
            "2025-05-19 08:21:08.404144: Model Saved: tem\n",
            "\n",
            "2025-05-19 08:21:38.189139: Epoch 37/40, Train: Loss = 0.0700, preLoss = 0.0700  \n",
            "\n",
            "2025-05-19 08:22:06.855309: Epoch 38/40, Train: Loss = 0.0696, preLoss = 0.0696  \n",
            "\n",
            "2025-05-19 08:22:35.730383: Epoch 39/40, Train: Loss = 0.0698, preLoss = 0.0698  \n",
            "2025-05-19 08:23:00.741461: Epoch 39/40, Test: Recall = 0.0715, NDCG = 0.0609  \n",
            "2025-05-19 08:23:00.764967: Model Saved: tem\n",
            "\n",
            "2025-05-19 08:23:25.721300: Epoch 40/40, Test: Recall = 0.0715, NDCG = 0.0609  \n",
            "2025-05-19 08:23:25.744611: Model Saved: tem\n"
          ]
        }
      ]
    }
  ]
}